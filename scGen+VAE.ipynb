{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oD_Vx5_NS3c"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YBABIxGONS3j"
   },
   "outputs": [],
   "source": [
    "import scgen\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sc.read(\"./tests/data/train_kang.h5ad\",\n",
    "                backup_url='https://drive.google.com/uc?id=1r87vhoLLq6PXAYdmyyd89zG90eJOFYLk')\n",
    "train_new = train[~((train.obs[\"cell_type\"] == \"CD4T\") &\n",
    "                    (train.obs[\"condition\"] == \"stimulated\"))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BkDMmt29NS3k",
    "outputId": "9504201e-9623-47c0-d87c-06769d1282ea"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "np.random.seed(43)\n",
    "\n",
    "class scDataset(Dataset):\n",
    "    def __init__(self, ann_array, transform=None):\n",
    "        self.X = ann_array.to_df().values\n",
    "        self.y = ann_array.obs['condition'].apply(lambda x: 0 if x == 'control' else 1).values\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self.X[idx, :], self.y[idx]\n",
    "\n",
    "def get_sample(adata, sample_size=1000):\n",
    "    '''\n",
    "        Get a sample of a given size from AnnData array\n",
    "    '''\n",
    "    barcodes = adata.obs.index.values\n",
    "    return train_new[np.random.choice(barcodes, sample_size), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lI3soxxLiHNm"
   },
   "source": [
    "## Custom VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.distributions\n",
    "\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions import kl_divergence\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Implementation for single-cell data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayers(nn.Module):\n",
    "    def __init__(self, n_input, n_layers, n_hidden, dropout_rate):\n",
    "        super(FCLayers, self).__init__()\n",
    "        modules = []\n",
    "        hidden_dims = [n_hidden]*n_layers\n",
    "        for in_size, out_size in zip([n_input]+hidden_dims, hidden_dims):\n",
    "            modules.append(nn.Linear(in_size, out_size, bias=True))\n",
    "            modules.append(nn.BatchNorm1d(out_size, momentum=0.01, eps=0.001))\n",
    "            modules.append(nn.ReLU())\n",
    "            modules.append(nn.Dropout(p=dropout_rate))\n",
    "        # modules.append(nn.Linear(hidden_dims[-1], out_dim))   # do not add fine layer to latent space\n",
    "        self.fc = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, *inputs):\n",
    "        input_cat = torch.cat(inputs, dim=-1)\n",
    "        return self.fc(input_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_input, n_layers, n_hidden, n_latent, dropout_rate=0.1, distribution='normal'):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc = FCLayers(n_input, n_layers, n_hidden, dropout_rate)\n",
    "        self.mean_encoder = nn.Linear(n_hidden, n_latent)\n",
    "        self.var_encoder = nn.Linear(n_hidden, n_latent)\n",
    "        self.var_activation = torch.exp\n",
    "        \n",
    "    def forward(self, x, *cat_list):\n",
    "        q = self.fc(x)\n",
    "        qz_m = self.mean_encoder(q)\n",
    "        qz_v = self.var_activation(self.var_encoder(q))  # we often apply an activation function exp() on variation to ensure positivity (more: https://avandekleut.github.io/vae/)\n",
    "        latent = Normal(qz_m, torch.sqrt(qz_v)).rsample() # reparametrized sample, allows differentiation (see more: https://stackoverflow.com/questions/60533150/what-is-the-difference-between-sample-and-rsample)\n",
    "        return qz_m, qz_v, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_latent, n_layers, n_hidden, n_output, dropout_rate=0.2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = FCLayers(n_latent, n_layers, n_hidden, dropout_rate)\n",
    "        self.linear_out = nn.Linear(n_hidden, n_output) # the last layer - to map results of FC neural network to original space, decode\n",
    "\n",
    "    def forward(self, x, *cat_list):\n",
    "        p = self.linear_out(self.fc(x, *cat_list))\n",
    "        return p"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, n_input, n_layers, n_hidden, n_latent, kl_weight=0.00005):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(n_input, n_layers, n_hidden, n_latent)\n",
    "        self.decoder = Decoder(n_latent, n_layers, n_hidden, n_output=n_input)\n",
    "        self.kl_weight = kl_weight\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(autoencoder, dataloader, epochs=20):\n",
    "    kl_weight = autoencoder.kl_weight\n",
    "    opt = torch.optim.Adam(autoencoder.parameters())\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch} is running...\", end='')\n",
    "        epoch_loss = 0\n",
    "        for x, y in dataloader:\n",
    "            # initialization\n",
    "            x = x.to(device)\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            # forward\n",
    "            qz_m, qz_v, z = autoencoder.encoder(x)\n",
    "            x_hat = autoencoder.decoder(z)\n",
    "            \n",
    "            # loss & backward\n",
    "            kl_div = kl_divergence(\n",
    "                Normal(qz_m, torch.sqrt(qz_v)),\n",
    "                Normal(0, 1),\n",
    "            ).sum(dim=1)\n",
    "            reconstruction_loss = ((x - x_hat)**2).sum()\n",
    "            loss = (0.5*reconstruction_loss + 0.5*(kl_div * kl_weight)).mean()\n",
    "            loss.backward()\n",
    "\n",
    "            # optimization step\n",
    "            opt.step()\n",
    "            epoch_loss += loss\n",
    "        print(\"loss: {:.3f}\".format(epoch_loss))\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 is running...loss: 716.804\n",
      "Epoch 1 is running..."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [29], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m autoencoder \u001B[38;5;241m=\u001B[39m VAE(n_input, n_layers, n_hidden, n_latent)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# TRAIN\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m autoencoder \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mautoencoder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# save parameters\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# torch.save(autoencoder.state_dict(), 'autoencoder.pt')\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# get learned model\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# autoencoder.load_state_dict(torch.load('autoencoder.pt'))\u001B[39;00m\n",
      "Cell \u001B[0;32mIn [25], line 22\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(autoencoder, dataloader, epochs)\u001B[0m\n\u001B[1;32m     20\u001B[0m reconstruction_loss \u001B[38;5;241m=\u001B[39m ((x \u001B[38;5;241m-\u001B[39m x_hat)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39msum()\n\u001B[1;32m     21\u001B[0m loss \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m0.5\u001B[39m\u001B[38;5;241m*\u001B[39mreconstruction_loss \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m0.5\u001B[39m\u001B[38;5;241m*\u001B[39m(kl_div \u001B[38;5;241m*\u001B[39m kl_weight))\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m---> 22\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# optimization step\u001B[39;00m\n\u001B[1;32m     25\u001B[0m opt\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/Workspace/Education/University/Toronto/vaegen/venv/lib/python3.9/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Workspace/Education/University/Toronto/vaegen/venv/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# DATASET & DATALOADER\n",
    "dataset = scDataset(train_new,      # get_sample(train_new) # You can train on a sample (to decrease duration of training)\n",
    "                    transform=ToTensor())\n",
    "\n",
    "# CREATE model\n",
    "n_input = dataset.X.shape[1] # number of features\n",
    "n_hidden = 100   # size of a hidden layer, 800 used in scGen\n",
    "n_latent = 10    # dimensionality of latent space\n",
    "n_layers = 2     # hidden layers in fully-connected NN\n",
    "\n",
    "autoencoder = VAE(n_input, n_layers, n_hidden, n_latent)\n",
    "\n",
    "# TRAIN\n",
    "autoencoder = train(autoencoder,\n",
    "                    dataloader=DataLoader(dataset, batch_size=32, shuffle=True),\n",
    "                    epochs=50)\n",
    "\n",
    "# save parameters\n",
    "# torch.save(autoencoder.state_dict(), 'autoencoder.pt')\n",
    "\n",
    "# get learned model\n",
    "# autoencoder.load_state_dict(torch.load('autoencoder.pt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Space visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qz_m, qz_v, latent_X = autoencoder.encoder(torch.tensor(train_new.to_df().values))\n",
    "latent_X.shape\n",
    "\n",
    "latent_adata = sc.AnnData(X=latent_X.detach().numpy(), obs=train_new.obs.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(latent_adata)\n",
    "sc.tl.umap(latent_adata)\n",
    "sc.pl.umap(latent_adata, color=['condition', 'cell_type'], wspace=0.4, frameon=False,\n",
    "           save='latentspace_pbi.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict stimulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extractor(\n",
    "    data,\n",
    "    cell_type,\n",
    "    condition_key,\n",
    "    cell_type_key,\n",
    "    ctrl_key,\n",
    "    stim_key,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a list of `data` files while filtering for a specific `cell_type`.\n",
    "    \"\"\"\n",
    "    cell_with_both_condition = data[data.obs[cell_type_key] == cell_type]\n",
    "    condition_1 = data[\n",
    "        (data.obs[cell_type_key] == cell_type) & (data.obs[condition_key] == ctrl_key)\n",
    "    ]\n",
    "    condition_2 = data[\n",
    "        (data.obs[cell_type_key] == cell_type) & (data.obs[condition_key] == stim_key)\n",
    "    ]\n",
    "    training = data[\n",
    "        ~(\n",
    "            (data.obs[cell_type_key] == cell_type)\n",
    "            & (data.obs[condition_key] == stim_key)\n",
    "        )\n",
    "    ]\n",
    "    return [training, condition_1, condition_2, cell_with_both_condition]\n",
    "\n",
    "\n",
    "def balancer(\n",
    "    adata,\n",
    "    cell_type_key,\n",
    "):\n",
    "    \"\"\"\n",
    "    Makes cell type population equal.\n",
    "    \"\"\"\n",
    "    class_names = np.unique(adata.obs[cell_type_key])\n",
    "    class_pop = {}\n",
    "    for cls in class_names:\n",
    "        class_pop[cls] = adata[adata.obs[cell_type_key] == cls].shape[0]\n",
    "    max_number = np.max(list(class_pop.values()))\n",
    "    index_all = []\n",
    "    for cls in class_names:\n",
    "        class_index = np.array(adata.obs[cell_type_key] == cls)\n",
    "        index_cls = np.nonzero(class_index)[0]\n",
    "        index_cls_r = index_cls[np.random.choice(len(index_cls), max_number)]\n",
    "        index_all.append(index_cls_r)\n",
    "\n",
    "    balanced_data = adata[np.concatenate(index_all)].copy()\n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_representation(autoencoder, adata, as_numpy=False):\n",
    "    qz_m, qz_v, latent_X = autoencoder.encoder(torch.tensor(adata.to_df().values))\n",
    "    if as_numpy:\n",
    "        return latent_X.detach().numpy()\n",
    "    else:\n",
    "        return sc.AnnData(X=latent_X.detach().numpy(), obs=adata.obs.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(autoencoder,\n",
    "            adata, \n",
    "            celltype_to_predict):\n",
    "    \n",
    "    cell_type_key = 'cell_type'\n",
    "    condition_key = 'condition'\n",
    "    ctrl_x = adata[adata.obs[condition_key] == 'control', :]\n",
    "    stim_x = adata[adata.obs[condition_key] == 'stimulated', :]\n",
    "    \n",
    "    # balance control and stimulated dataset\n",
    "    ctrl_x = balancer(ctrl_x, cell_type_key)\n",
    "    stim_x = balancer(stim_x, cell_type_key)\n",
    "    \n",
    "    # Get control adata (we predict stimulated for it)\n",
    "    ctrl_pred = extractor(\n",
    "            adata,\n",
    "            celltype_to_predict,\n",
    "            condition_key,\n",
    "            cell_type_key,\n",
    "            ctrl_key='control',\n",
    "            stim_key='stimulated',\n",
    "        )[1]\n",
    "\n",
    "    # Equalize the sized od control and stimulated dataset\n",
    "    eq = min(ctrl_x.X.shape[0], stim_x.X.shape[0])\n",
    "    cd_ind = np.random.choice(range(ctrl_x.shape[0]), size=eq, replace=False)\n",
    "    stim_ind = np.random.choice(range(stim_x.shape[0]), size=eq, replace=False)\n",
    "    ctrl_adata = ctrl_x[cd_ind, :]\n",
    "    stim_adata = stim_x[stim_ind, :]\n",
    "\n",
    "    # compute mean of control/stimulated in latent space\n",
    "    latent_ctrl = np.mean(get_latent_representation(autoencoder, ctrl_adata, as_numpy=True), axis=0)\n",
    "    latent_stim = np.mean(get_latent_representation(autoencoder, stim_adata, as_numpy=True), axis=0)\n",
    "\n",
    "    delta = latent_stim - latent_ctrl\n",
    "    \n",
    "    # get latent representation of anndata we want to predict stimulated for\n",
    "    latent_cd = get_latent_representation(autoencoder, ctrl_pred, as_numpy=True)\n",
    "\n",
    "    stim_pred = delta + latent_cd\n",
    "    \n",
    "    # decode predicted stimulated\n",
    "    predicted_cells = (\n",
    "        autoencoder.decoder(torch.Tensor(stim_pred)).cpu().detach().numpy()\n",
    "    )\n",
    "\n",
    "    predicted_adata = sc.AnnData(\n",
    "        X=predicted_cells,\n",
    "        obs=ctrl_pred.obs.copy(),\n",
    "        var=ctrl_pred.var.copy(),\n",
    "        obsm=ctrl_pred.obsm.copy(),\n",
    "    )\n",
    "    return predicted_adata, delta\n",
    "\n",
    "\n",
    "predicted_adata, delta = predict(autoencoder, train_new, celltype_to_predict='CD4T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_adata = train[((train.obs['cell_type'] == 'CD4T') & (train.obs['condition'] == 'control'))]\n",
    "stim_adata = train[((train.obs['cell_type'] == 'CD4T') & (train.obs['condition'] == 'stimulated'))]\n",
    "\n",
    "eval_adata = ctrl_adata.concatenate(stim_adata, predicted_adata)\n",
    "\n",
    "sc.tl.pca(eval_adata)\n",
    "sc.pl.pca(eval_adata,\n",
    "          color=\"condition\",\n",
    "          frameon=False,\n",
    "          save='pred_eval.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCGEN:  Perturbation Prediction <a class=\"anchor\" id=\"scgen-perturbation-prediction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBplB3HbNS3n"
   },
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkNjW-3qNS3o",
    "outputId": "25f5cae3-9626-4efc-c600-dec21ca0f4a3"
   },
   "outputs": [],
   "source": [
    "scgen.SCGEN.setup_anndata(train_new, batch_key=\"condition\", labels_key=\"cell_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiQXbVm8NS3q"
   },
   "source": [
    "## Creating and Saving the model¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k19PKKcLNS3q",
    "outputId": "233aee5b-4c09-48e1-9497-d7453866f6ab"
   },
   "outputs": [],
   "source": [
    "model = scgen.SCGEN(train_new)\n",
    "model.save(\"../saved_models/model_perturbation_prediction.pt\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwBPgbSDNS3r"
   },
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnfjH0azNS3r",
    "outputId": "e3564592-df63-435e-c687-d20fdee3b7b4"
   },
   "outputs": [],
   "source": [
    "model.train(\n",
    "    max_epochs=100,\n",
    "    batch_size=32,\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIcut2-qNS3r"
   },
   "source": [
    "### Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpvJl__7NS3r",
    "outputId": "0f776b0b-4cf3-4145-873a-367435becfb9"
   },
   "outputs": [],
   "source": [
    "latent_X = model.get_latent_representation()\n",
    "latent_adata = sc.AnnData(X=latent_X, obs=train_new.obs.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjnueaPvNS3s",
    "outputId": "8e482417-ebb0-4b23-f512-2aa7cb2f9e92"
   },
   "outputs": [],
   "source": [
    "sc.pp.neighbors(latent_adata)\n",
    "sc.tl.umap(latent_adata)\n",
    "sc.pl.umap(latent_adata, color=['condition', 'cell_type'], wspace=0.4, frameon=False,\n",
    "           save='latentspace_batch32_klw000005_z100__100e.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egEth5KbNS3s"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hL77Ewq3NS3s"
   },
   "source": [
    "After training the model you can pass the adata of the cells you want to perturb. Here we pass unperturbed CD4T cells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLepn7n7NS3t"
   },
   "source": [
    "Here the 'adata' contains the cells that you want estimate the perturbation based on them. we set \"ctrl\" to our control labels and \"stim\" to our stimulated labels. If you apply it in another context just set \"ctrl\" :\"your_control_label\" and \"stim\":\"your_stimulated_label\". the returned value is a numpy matrix of our predicted cells and the second one is the difference vector between our conditions which might become useful later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IYUihVLNS3t",
    "outputId": "7070d04c-9422-49bc-e82c-4ea789d32d2d"
   },
   "outputs": [],
   "source": [
    "pred, delta = model.predict(\n",
    "    ctrl_key='control',\n",
    "    stim_key='stimulated',\n",
    "    celltype_to_predict='CD4T'\n",
    ")\n",
    "pred.obs['condition'] = 'pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkTZKnBpNS3t"
   },
   "source": [
    "In the previous block, the difference between conditions is by default computed using all cells (obs_key=\"all\"). However, some times you might have a rough idea that which groups (e.g. cell types) are close to your cell type of interest. This might give you more accurate predictions. For example, we can restrict the delta computation only to CD8T and NK cells. We provide dictionary in form of obs_key={\"cell_type\": [\"CD8T\", \"NK\"]} which is telling the model to look at \"cell_type\" labels in adata (here: train_new) and only compute the delta vector based on \"CD8T\" and \"NK\" cells :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsBfHrhlNS3t"
   },
   "source": [
    "pred, delta = scg.predict(adata=train_new, adata_to_predict=unperturbed_cd4t, conditions={\"ctrl\": \"control\", \"stim\": \"stimulated\"}, cell_type_key=\"cell_type\", condition_key=\"condition\", obs_key={\"cell_type\": [\"CD8T\", \"NK\"]})`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CH1yyXFUNS3u"
   },
   "source": [
    "## Evaluation of the predcition¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x475QS9fNS3u"
   },
   "source": [
    "#### Extracting both control and real stimulated CD4T cells from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iCzIRcZNS3u"
   },
   "outputs": [],
   "source": [
    "ctrl_adata = train[((train.obs['cell_type'] == 'CD4T') & (train.obs['condition'] == 'control'))]\n",
    "stim_adata = train[((train.obs['cell_type'] == 'CD4T') & (train.obs['condition'] == 'stimulated'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpOpUhHSNS3u"
   },
   "source": [
    "Merging predicted cells with real ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkxsFkdgNS3u"
   },
   "outputs": [],
   "source": [
    "eval_adata = ctrl_adata.concatenate(stim_adata, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSCPOTtANS3u"
   },
   "source": [
    "### Embedding all real and predicted cells in one PCA plot¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FI06I8LxNS3u",
    "outputId": "24f3e4e4-3f17-4895-959e-80385c891521"
   },
   "outputs": [],
   "source": [
    "sc.tl.pca(eval_adata)\n",
    "sc.pl.pca(eval_adata, color=\"condition\", frameon=False,\n",
    "           save='pred_stim_b32_klw000005_z100__100e.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mr4o1nsuNS3v"
   },
   "source": [
    "## Mean correlation plot¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kYH5pcvNS3v"
   },
   "source": [
    "You can also visualize your mean gene expression of your predicted cells vs control cells while highlighting your genes of interest (here top 10 differentially expressed genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pTuzHvXNS3v",
    "outputId": "fccb53d0-3916-431a-88b2-b6b16fe3a88e"
   },
   "outputs": [],
   "source": [
    "CD4T = train[train.obs[\"cell_type\"] ==\"CD4T\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PkDbx-3NS3v",
    "outputId": "f4dce0e4-4e63-4437-99f0-d7c06151cbb0"
   },
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(CD4T, groupby=\"condition\", method=\"wilcoxon\")\n",
    "diff_genes = CD4T.uns[\"rank_genes_groups\"][\"names\"][\"stimulated\"]\n",
    "print(diff_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENAu5BgINS3v",
    "outputId": "1d3501e8-fd1c-4edb-ecb8-c6f65dc9232c"
   },
   "outputs": [],
   "source": [
    "r2_value = model.reg_mean_plot(\n",
    "    eval_adata,\n",
    "    axis_keys={\"x\": \"pred\", \"y\": \"stimulated\"},\n",
    "    gene_list=diff_genes[:10],\n",
    "    labels={\"x\": \"predicted\", \"y\": \"ground truth\"},\n",
    "    path_to_save=\"./reg_mean1.pdf\",\n",
    "    show=True,\n",
    "    legend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sv5SiqINS3w"
   },
   "source": [
    "You can also pass a list of differentially epxressed genes to compute correlation based on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcgCoG4-NS3w",
    "outputId": "1fe91d92-7f9b-4339-ad63-e732ea459a94"
   },
   "outputs": [],
   "source": [
    "r2_value = model.reg_mean_plot(\n",
    "    eval_adata,\n",
    "    axis_keys={\"x\": \"pred\", \"y\": \"stimulated\"},\n",
    "    gene_list=diff_genes[:10],\n",
    "    top_100_genes= diff_genes,\n",
    "    labels={\"x\": \"predicted\",\"y\": \"ground truth\"},\n",
    "    path_to_save=\"./reg_mean1.pdf\",\n",
    "    show=True,\n",
    "    legend=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-O2MRz0NS3w"
   },
   "source": [
    "### Violin plot for a specific gene¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMlwt2RlNS3w"
   },
   "source": [
    "Let's go deeper and compare the distribution of \"ISG15\", the top DEG between stimulated and control CD4T cells between predcited and real cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrS4urt3NS3x",
    "outputId": "adfb35ae-45f2-43a1-a7fa-765ae3b24d05"
   },
   "outputs": [],
   "source": [
    "sc.pl.violin(eval_adata, keys=\"ISG15\", groupby=\"condition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bi7vJKddNJU8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
